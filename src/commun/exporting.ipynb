{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fa94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.6.2) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from enhancing.modules.stage1.vitvqgan import ViTVQ\n",
    "from enhancing.modules.stage1.layers import ViTEncoder as Encoder, ViTDecoder as Decoder\n",
    "from enhancing.modules.stage1.quantizers import VectorQuantizer, GumbelQuantizer\n",
    "from enhancing.utils.general import get_config_from_file, initialize_from_config\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from /home/nvidia/semcom_ws/src/commun/commun/checkpoint/imagenet_vitvq_small.ckpt\n",
      "ONNX model saved: encoder_small_1.onnx\n",
      "ONNX model saved: encoder_small_2.onnx\n",
      "ONNX model saved: encoder_small_3.onnx\n",
      "ONNX model saved: encoder_small_4.onnx\n",
      "ONNX model saved: encoder_small_6.onnx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = get_config_from_file(\"/home/nvidia/semcom_ws/src/commun/commun/imagenet_vitvq_encoder_small.yaml\")\n",
    "vitvq = initialize_from_config(config.model)\n",
    "for param in vitvq.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for b in [1, 2, 3, 4, 6]:\n",
    "    \n",
    "    # torch.onnx.export(\n",
    "    #     model.encoder, dummy_input,\n",
    "    #     f\"vqgan_encoder_{b}.onnx\",\n",
    "    #     export_params=True,\n",
    "    #     opset_version=13,\n",
    "    #     dynamic_axes=None,          # IMPORTANT for INT8\n",
    "    #     do_constant_folding=True\n",
    "    # )\n",
    "    dummy_input = torch.randn(b, 3, 256, 256, device=\"cuda\")\n",
    "    torch.onnx.export(\n",
    "        vitvq, dummy_input, f\"./encoder_small_{b}.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        dynamic_axes=None,          # IMPORTANT for INT8\n",
    "        do_constant_folding=True\n",
    "    )\n",
    "    print(f\"ONNX model saved: encoder_small_{b}.onnx\")\n",
    "    del dummy_input\n",
    "\n",
    "# trtexec --onnx=encoder_small_1.onnx --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = get_config_from_file(\"/home/nvidia/semcom_ws/src/commun/commun/imagenet_vitvq_base.yaml\")\n",
    "vitvq: ViTVQ = initialize_from_config(config.model)\n",
    "vitvq.init_from_ckpt(\"/home/nvidia/semcom_ws/src/commun/commun/checkpoint/imagenet_vitvq_base.ckpt\")\n",
    "for param in vitvq.parameters():\n",
    "    param.requires_grad = False\n",
    "vitvq.eval()\n",
    "# vitvq.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba659cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = vitvq.encoder\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 256, 256)\n",
    "torch.onnx.export(vitvq.encoder, dummy_input, \"./encoder_base.onnx\", export_params=True)\n",
    "print(\"ONNX model saved: encoder_base.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = vitvq.encoder\n",
    "\n",
    "dummy_input = torch.randn(1, 1024, 512)\n",
    "torch.onnx.export(vitvq.decoder, dummy_input, \"./decoder_base.onnx\", export_params=True)\n",
    "print(\"ONNX model saved: decoder_base.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf41e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trtexec --onnx=encoder.onnx --saveEngine=encoder.trt --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309cb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = get_config_from_file(\"/home/nvidia/semcom_ws/src/commun/commun/imagenet_vitvq_base.yaml\")\n",
    "encoder = Encoder(image_size=256, patch_size=8, dim=768, depth=12, heads=12, mlp_dim=3072)\n",
    "dummy_input = torch.randn(1, 3, 256, 256)\n",
    "torch.onnx.export(encoder, dummy_input, \"./encoder_base.onnx\", export_params=True)\n",
    "# vitvq.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90553df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
