{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde06f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from enhancing.modules.stage1.vitvqgan import ViTVQ\n",
    "from enhancing.modules.stage1.layers import ViTEncoder as Encoder, ViTDecoder as Decoder\n",
    "# from enhancing.modules.stage1.quantizers import VectorQuantizer, GumbelQuantizer\n",
    "from enhancing.utils.general import get_config_from_file, initialize_from_config\n",
    "\n",
    "from taming.models.vqgan import VQModel\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753f512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "Restored from /home/leonard/semcom_ws/src/commun/commun/checkpoint/vqgan_f16_16384.ckpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = get_config_from_file(\"/home/leonard/semcom_ws/src/commun/commun/vqgan_f16_16384.yaml\")\n",
    "vitvq: VQModel = initialize_from_config(config.model)\n",
    "vitvq.init_from_ckpt(\"/home/leonard/semcom_ws/src/commun/commun/checkpoint/vqgan_f16_16384.ckpt\")\n",
    "for param in vitvq.parameters():\n",
    "    param.requires_grad = False\n",
    "vitvq.eval()\n",
    "# vitvq.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a2478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "ONNX model saved: decoder_small_1.onnx\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "ONNX model saved: decoder_small_2.onnx\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "ONNX model saved: decoder_small_3.onnx\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "ONNX model saved: decoder_small_4.onnx\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ViTDecoder([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "ONNX model saved: decoder_small_6.onnx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for b in [1]: #, 2, 3, 4, 6]:\n",
    "    dummy_input = torch.randn(b, 1024, 512)\n",
    "    torch.onnx.export(vitvq.decoder, dummy_input, f\"./vqgan_{b}.onnx\", export_params=True)\n",
    "    print(f\"ONNX model saved: vqgan_{b}.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trtexec --onnx=decoder_base_1.onnx --fp16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
